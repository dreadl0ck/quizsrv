- question: What is the end-to-end principle?
  answer: Ensuring reliadbility is considered heavy lifting, and should therefore only be done on the edges of the connection, to avoid overloading the transit routers.

- question: What is the job of TCP according to Vint Cerf?
  answer: To take a stream of messages produced by one host and reproduce the stream at a foreign receiving host without change.

- question: Name three core attributes of TCP
  answer: |
    - Connection oriented
    - Reliable
    - Byte-stream oriented

- question: Which reliability guarantees are provided by TCP?
  answer: |
    - Error detection
    - Error correction
    - Notification of problems

- question: What are the flag bits in the TCP header used for?
  answer: To indicate operation that are in progress.

- question: What are the TCP options used for?
  answer: To manage control of connection details and negotiation parameters.

- question: Name the core components of the TCP header
  answer: |
    - Source and Destination Port
    - Sequence Number
    - Acknowledgement Number
    - Flags
    - Header Length
    - Window Size
    - Checksum
    - Options

- question: What is the sequence number in TCP used for?
  answer: To communicate the offset of the first bit in the included data portion to the other end.

- question: What is the acknowledgement number in TCP used for?
  answer: To indicate the offset of the next bit in the byte stream the other end wants to receive.

- question: When a client sends sequence number 10 and ack number 30, what will the server reply?
  answer: Seq=30, ACK=11

- question: Which variables have to be initialized in order to create a TCP connection?
  answer: |
    - Sequence Number
    - Buffer sizes
    - Round Trip Time (RTT)

- question: What does ISN stand for?
  answer: Initial Sequence Number

- question: Why do buffer sizes have to be negotiated on connection setup?
  answer: To avoid over-running the receivers.

- question: Briefly explain the TCP three way handshake
  answer: |
    1. Active open: client sends SYN segment with initial seq number to server
    2. Passive open: server allocates buffers, specifies server side initial seq number and replies with SYNACK segment
    3. Client replies with ACK, which may contain data

- question: What happens during the TCP SYN attack?
  answer: |
    One or multiple clients send only the initial SYN packets, in order to have the server allocate buffer space for them.
    Since no further packets are sent for the opened connection, the server will run out of resources quickly and fail to handle legitimate traffic.

- question: Briefly describe the TCP connection termination
  answer: |
    Each direction shuts down independently.
    1. Client sends FIN control segment
    2. Server replies with ACK, closes connection and sends FIN
    3. Client replies with ACK
    4. Server receives ACK and closes connection

- question: Is it possible that one side of a TCP connection is closed, but the other one is still used to send data?
  answer: Yes, so called half close, a TCP connection is full duplex and both sides can communicate independently.

- question: What flag does a TCP client set to establish a connection?
  answer: SYN flag

- question: What does the positive acknowledgement mechanism in TCP do?
  answer: Confirming to the sender that the segment was received successfully.

- question: Can TCP segment acknowledgements be accumluated?
  answer: Yes! Sending a packet for acknowledging every segment individually would perform badly.

- question: How does TCP handle problems in transmission?
  answer: Checksum to detect errors in transfered data, sequence numbers for data segments, positive acknowledgements.

- question: What is the procedure if some segments get lost?
  answer: Lost segments are being retransmitted.

- question: What indicates that a segment got lost?
  answer: When the round trip timer expired (RTO)

- question: How can the ideal RTO be determined?
  answer: By measuring the Round Trip Time.

- question: What does RTO stand for?
  answer: Retransmission Timeout

- question: What does RTT stand for?
  answer: Round Trip Time

- question: What is the speed of light in a fiber medium?
  answer: 200 km/ms

- question: How is the RTT being calculated?
  answer: Time it takes for the signal to be transmitted from sender to receiver, plus the time for the acknowledgement for receipt to travel back.

- question: How is the RTT being estimated?
  answer: |
    1) SampleRTT is measured for packets that have been transmitted _once_.
    2) SmoothedRTT is the weighted avergae of the collected SampleRTT value.s
    3) RTTVAR is the variation of the RTT.

- question: What is the formula to calculate the TCP timeout interval?
  answer: RTO = SRTT + max(Clock, 4 * DevRTT)

- question: Is the RTO constant during a TCP session?
  answer: No! It is often recalculated in order to react to changes in latency.

- question: What does the term bufferbloat refer to?
  answer: The undesirable latency that comes from the existence of excessively large (full) buffers in network communication systems.

- question: What happens during queueing?
  answer: |
    1) TCP stream starts sending traffic
    2) Large buffer on bottleneck node starts to fill up
    3) TCP does not notice packet loss and increases CWND
    4) Large buffer is completely full
    5) Packet loss is only detected when buffer is already full
    6) Huge delay and jitter, bad throughput

- question: How will a TCP receiver react upon arrival of an in-order segment with the expected seq number, if all data up to the seq number has been ACKed?
  answer: The receiver will wait up to 500ms for the next segment. If no next segment arrives, the ACK will be sent out.

- question: How will a TCP receiver react upon arrival of an in-order segment with the expected seq number, if one other segment has an ACK pending?
  answer: Receiver will immediately sent cumulative ACK, acknowledging both in-order segments.

- question: How will a TCP receiver react upon arrival of an out-of-order segment with a sequence number higher than expected?
  answer: If a gap is detected, the receiver will immediately send a duplicate ACK, indicating the seq number of the next expected byte.

- question: How will a TCP receiver react upon arrival of a segment that partially or completely fills a gap?
  answer: Receiver will immediately send ACK, if that segment starts at the lower end of the gap.

- question: What is flow control in TCP?
  answer: |
    A mechanism used by the sender to determine how much pipelining can be done so that the receiving end is not overflown.
    Regulated by a _variable sliding window_ (via window advertisement): the _receive window_ (rwnd).
    Flow control uses pipeling to improve throughput and is essential for performance.

- question: What is congestion control in TCP?
  answer: |
    A mechanism to overcome problems due to congestion detected on the network, using the congestion window.

- question: What is the MTU of an ethernet frame?
  answer: 1500 bytes for a normal frame, 9000 bytes for jumbo frames.

- question: What happens during pipelining?
  answer: |
    Pipelining is a mechanism used for flow control, and allows _W_ segments to be outstanding, in order to increase throughput.
    _W_ can be sent every RTT, to fill the network path: _W = BDP_ (Bandwidth Delay Product).

- question: How does the SYN attack relate to the receive window?
  answer: The buffer for the receive window allocated for each client is essentially wasted, because the clients never complete the three way handshake.

- question: How does the sliding window mechanism improve throughput?
  answer: By utilizing the bandwidth more effectively, essentially saturating the network wuth packets.

- question: What is considered the upper bound for the throughput of TCP connection?
  answer: The receive window (rwnd).

- question: What is the difference between goodput and throughput?
  answer: |
    Throughput is the measurement of all data flowing through a link no matter if it is useful data or not (also retransmissions), while goodput is focused on useful (e.g. application) data only.

- question: Which parameters are kept by a TCP _sender_?
  answer: |
    - LastByteAcked
    - LastByteSent
    - LastByteWritten (not yet sent out)

- question: Which parameters are kept by a TCP _receiver_?
  answer: |
    - LastByteRead
    - NextByteExpected
    - LastByteReceived

- question: What conditions must hold regarding the parameters on the _sender_ side?
  answer: |
    1) LastByteAcked <= LastByteSent
    2) LastByteSent <= LastByteWritten

- question: What conditions must hold regarding the parameters on the _receiver_ side?
  answer: |
    1) LastByteRead <= NextByteExpected (not possible to read a byte if all preceding bytes haven't been acked yet)
    2) NextByteExpected <= LastByteRcvd + 1

- question: What equation needs to be true on the receiver side to avoid overflowing the buffer?
  answer: LastByteRcvd - LastByteRead <= RcvBuffer

- question: What is the equation for the _amount of free space_ on the receiver side (rwnd)?
  answer: AdvertisedWindow = RcvBuffer - ((NextByteExpected-1) - LastByteRead)

- question: How can the effective window be calculated on the sender side?
  answer: EffectiveWindow = AdvertisedWindow - (LastByteSent - LastByteAcked)

- question: Which equation has to hold true on the sender side, regarding the effective window?
  answer: LastByteSent - LastByteAcked <= AdvertisedWindow

- question: What is the relation between an optimal receive window and the link capacity?
  answer: The receive window is the upper bound for throughput, but links along the path can have different bandwidth as well.

- question: How can the Bandwidth Delay Product be calculated?
  answer: bandwidth (bits per second) of bottneck link * round trip time (in seconds)

- question: What does the BDP describe?
  answer: The bandwith delay caused by the bottleneck link along a network path.

- question: What is considered a large BDP and how are networks called that suffer from this?
  answer: |
    Large BDP: > 10^5 bits > 12.5 KBytes
    Called LFN = long fat network

- question: What are problems with LFNs?
  answer: |
    - receive window size (wasting bandwidth)
    - need better RTT measurements
    - wrapping of sequence numbers (32bits)
    - packet loss reduces throughput dramatically

- question: How many different values can be represented using 16 bits?
  answer: 2^16 = 65536 distinct values

- question: How many bits are reserved for the receive window in the TCP header?
  answer: 16 bits

- question: What is the maximum possible window size when using only the receive window field?
  answer: 16 bit field => max 64 Kbytes

- question: Is the use of TCP options compulsory?
  answer: No, the use of options is optional.

- question: How can the window size be increased beyond the limit imposed by the size of its field in the TCP header?
  answer: By setting the window scaling factor in the TCP options.

- question: Could the Maximum Segment Size be set to a value bigger than the MTU?
  answer: Yes, but the MTU would still be the limit.

- question: What does MSS stand for?
  answer: Maximum Segment Size

- question: What is the purpose of the MTU?
  answer: Defines the largest packet size that can travel through the network in bytes.

- question: What does MTU stand for?
  answer: Maximum Transmission Unit

- question: What does the Path MTU refer to?
  answer: |
    The smallest MTU on an IP path, as discovered by Path MTU Discovery, or in other words: the largest packet size that will traverse the network without fragmentation.

- question: What should the receive window be equal to?
  answer: Should be equal to the bandwidth delay product (BDP).

- question: Which option was introduced by RFC 1323 "TCP Large Windows Extensions"?
  answer: The window scaling (WSCALE) option.

- question: When is the WSCALE option negotiated and can it be renegotiated during a session?
  answer: Negotiated at start up (in SYN packet), cannot be renegotiated.

- question: What is the purpose of the timestamp option rgarding the RTT calculation?
  answer: Contains a timestamp for every segment, used for more accurate RTT calculation, based on each received ACK.

- question: Name two benefits of the TCP timestamp option
  answer: |
    1) Receiver echoes back what was received: no need for clock synchronization
    2) Provides protection against wrapped sequence numbers (PAWS)

- question: What does SACK stand for?
  answer: Selective Ackknowledgement

- question: What is the purpose of SACK?
  answer: Allows to acknowledge out-of-order segments selectively, can be combined with selective retransmission.

- question: What is the purpose of DSACK?
  answer: Acknowledges duplicate packets using the SACK field

- question: Is congestion avoidable for large networks?
  answer: No! Overprovisioning the network so that it could always guarantee all users to communicate at their full bandwidth would not be profitable.

- question: What are the two possible approaches to congestion control?
  answer: |
    1) End-to-end congestion control
    2) Network-assisted congestion control

- question: Which congestion control approach was chosen for TCP?
  answer: End-to-end congestion control (cwnd) & network assisted congestion control (ECN flag)

- question: Explain the principles used for end-to-end congestion control
  answer: |
    - No explicit feedback from network
    - Congestion inferred from end-system observed loss and delay

- question: Explain the principles used for network-assisted congestion control
  answer: |
    - Routers provide feedback to end systems
      - single bit indicating congestion (explicit notification)
      - explicit rate at which sender should send at is communicated

- question: Which side of a TCP connection is responsible for congestion control?
  answer: The sender side. Since TCP connections are full duplex, both client and server choose a congestion algorithm for sending data to the other side.

- question: During a single TCP session, can both sides run different congestion algorithms?
  answer: Yes!

- question: Which four components does a congestion control algorithm have?
  answer: |
    - Slow start
    - Congestion avoidance
    - Fast retransmit
    - Fast recovery

- question: Name the different TCP implementations that have been created during the evolution of the TCP stack
  answer: |
    1) TCP Tahoe was the original implementation
    2) TCP Reno implemented fast recovery
    3) TCP New Reno improves retransmission during the fast recovery phase of TCP Reno

- question: What is the purpose of the congestion window? On which side of a connection is it being maintained?
  answer: Used to restrict data flow to less than the receiver's buffer size when congestion occurs. Sender side.

- question: How can the allowed congestion window size be calculated?
  answer: Allowed window = min(rwnd, cwnd)

- question: How can the presence of congestion on the network be detected?
  answer: |
    - Timeouts
    - Duplicate ACKs

- question: Is the congestion window constant?
  answer: No, it is recalculated based on the arrival of ACKs. This is called self-clocking.

- question: Briefly explain how the slow start congestion control phase works
  answer: |
    - At start cwnd is equal to min(4*MSS, max(2*MSS, 4380 bytes))
    - To avoid wasting bandwidth, initial increase is exponential
    - Doubling cwnd every RTT: cwnd = cwnd + MSS (when ACK arrives)

- question: Explain the purpose of the Slow Start Threshold (ssthresh)
  answer: |
    Determines if _cwnd_ should follow slow start or congestion control.
    Initially very high (equal to rwnd), decreases after congestion.

- question: What does AIMD stand for?
  answer: Additive Increase Multiplicative Decrease

- question: In which congestion control phase is AIMD used?
  answer: During the congestion avoidance phase.

- question: Explain multiplicative decrease during congestion avoidance
  answer: |
    Congestion window is halved for every lost segment, but it cannot be decreased below 1 MSS.

- question: Explain additive increase during congestion avoidance
  answer: |
    Every time an ACK arrives: _cwnd += MSS * (MSS / cwnd)_
    Every RTT congestion window increases by 1 MSS.

- question: Explain how TCP attempts to implement fairness
  answer: Instead of starting to send enough data to directly fill the advertised receive window, TCP tries to sense the amount of congestion on the network, by exponentially ramping up data volume during the slow start phase.

- question: How can the TCP sending rate be calculated?
  answer: rate = cwnd / RTT (bytes / sec)

- question: How does TCP react to a single timeout?
  answer: |
    ssthresh = bytes_in_flight / 2
    Slow start up to cwnd > ssthresh, then congestion avoidance.

- question: How does TCP react to three duplicate ACKs?
  answer: |
    Saw toothed behavior of congestion avoidance.
    Fast recovery, first implemented in TCP Reno.

- question: What are the bytes in flight?
  answer: The amount of data that has been sent but not yet acknowledged.

- question: Explain the fast retransmit phase
  answer: |
    - If sender receives 3 ACKs for the same data
    - resends segment before timer expires
    - waits for an ACK of the entire transmit window before returning to congestion avoidance

- question: Which TCP implementation is used by systems nowadays?
  answer: TCP New Reno

- question: What are advantages of TCP New Reno with regard to congestion control?
  answer: It is able to detect _multiple losses_, improves further on fast retransmits compared to previous implementations.

- question: Briefly describe the core strategy deployed by TCP New Reno regarding congestion control
  answer: |
    - Keeps track of last un-acked packet when entering fast recovery
    - On every ACK increase cwnd by one MSS
    - When last ACK arrives, return to congestion avoidance, set cwnd to value when entering fast recovery

- question: Provide the equation for the congestion window if loss is detected
  answer: cwnd = cwnd - a*cwnd (multiplicative decrease)

- question: Provide the equation for the congestion window if an ACK arrives
  answer: cwnd = cwnd + b/cwnd (additive increase)

- question: Name am improved TCP implementation particularly for wireless networks
  answer: Westwood TCP (improves on Reno)

- question: Name the TCP implementation suitable for large BDP networks
  answer: High-speed TCP (HSTCP)

- question: Name the TCP implementation that slightly increases throughput
  answer: Scalable TCP (congestion window does not oscillate)

- question: What is the standard TCP implementation enabled on linux nowadays?
  answer: TCP Cubic

- question: What is a more recent TCP implementation than TCP Cubic?
  answer: Bottleneck Bandwidth and Round-trip propagation time (BBR) from Google

- question: Formulate the fairness goal for TCP
  answer: If _K_ TCP sessions share same bottleneck link of bandwidth _R_, each should have average rate of _R/K_.

- question: Why do multimedia apps often not make use of TCP?
  answer: Because they do not want rate throttled by congestion control.

- question: What can be done to get a higher share of the network, while still using TCP?
  answer: An additional connection could be openened, nothing prevents an app from using multiple connections between two hosts.

- question: Which problem does MPTCP solve?
  answer: When IP addresses change, TCP connections have to be re-established.

- question: What does MPTCP stand for?
  answer: Multi Path Transport Layer Protocol

- question: How does a client communicate to a server that he supports MPTCP?
  answer: By sending the MP_CAPABLE TCP option with the SYN packet during the three way handshake.

- question: What does SCTP stand for?
  answer: Stream Control Transmission Protocol

- question: Is SCTP compatible to TCP?
  answer: No
